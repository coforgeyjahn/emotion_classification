Introduction:
Emotion detection of tweets using Neural Networks
The problem we have chosen to research is that of emotion detection and classification of text, specifically tweets from Twitter (X). Being able to analyze this informal language has become important for understanding public thoughts. Working with classification of tweets is a particularly interesting challenge, due to tweets being limited to only 280 characters and often containing words that are slang or informal. Thus the issue of classifying tweets into emotions with such few characters is one presenting unique challenges.
Neural networks are able to perform well on data with nonlinear relationships, thus have shown great promise in text classification tasks. This study will focus on the use of neural networks to classify emotions in tweets, comparing the performance of Convolutional Neural Networks (CNNs), Artificial Neural Networks (ANNs), and Recurrent Neural Networks (RNN). CNNs have proven to be useful when attempting to capture local patterns and relationships through convolutional layers, and are commonly used in image classification (9). ANNs excel with mathematically complex challenges, and perform best on simpler classification problems. RNNs are popularly used in more complex problems and in Natural Language Processing (2).
In emotion classification of text, all of these models have potential but will likely face distinctive challenges, such as overfitting, underfitting and computational complexity. This paper will analyze the strengths and weaknesses of CNNs, ANNs, and RNNs in emotion classification of tweets, evaluating the performance of each based on accuracy and computational efficiency.

Literature Review:

In this literature review, we will compare the methodologies, selected datasets, and evaluations of three research papers. The first paper is associated with the dataset we have chosen to use - “CARER: Contextualized Affect Representations for Emotion Recognition” which we will reference as “CARER”. This study was done in the Association for Computational Statistics department in Brussels, Belgium in 2018. The second is “Semantic Emotion Neural Network for Emotion Recognition from Text”, supported by the Basic Science Research Program through the National Research Foundation of Korea (NRF) in 2019. We will reference this as “SENN”. The third paper, “Emotion Detection in Text: a Review” was produced by students at the University of North Carolina (UNC) in 2018. We will cite this as “UNC”.
CARER cites that they rely on hashtags to define the emotion categories. They categorize 339 hashtags used in tweets into 8 categories of emotion. For instance tweets using the hashtags “#hope” or “#secure” is classified into the emotion “trust”. The authors then present a graph-based algorithm designed to generate emotion-rich representations from a large-scale emotion corpus. The algorithm they use extracts and processes important contextual information to create these representations. Next they normalize, tokenize, and construct separate graphs for objective tweets and subjective tweets, where nodes represent tokens and edges represent relationships between words. Finally, the patterns that they find between words and emotions are weighted using a customized version of tf-idf that they call pattern frequency-inverse emotion frequency (pf-ief), which helps them greatly with classification.
SENN proposed a new neural network architecture called SENN (Semantic-Emotion Neural Network) which is made up of two sub-networks. The first subnetwork uses bidirectional Long-Short Term Memory (BiLSTM) to capture contextual information and focus on semantic relationships. The second sub-network uses the convolutional neural network (CNN) to extract emotional features and focuses on the emotional relationship between words from the text. By
doing this they are able to capture semantic/syntactic information and emotional information (4). The metric they focused on in this study was the F1-score, and they found that the highest F1 score was achieved with their SENN model with batch size 128, learning rate .01, dropout of 0.5, and number of filters 100 or 200. In this paper, for our CNN we will utilize these hyperparameters.
In their research, UNC gathers data from more than 50 emotion-recognition-in-text studies and compares and contrasts the results. They found that in Twitter specifically, using hashtags as labels will achieve an accuracy of between 75% and 91%. They noted that using an SVM with hashtags as labels can attain ~82% accuracy, with an average F1-score of 66%, suggesting that an SVM, while reasonable, might not be the most optimal choice for an emotion recognition model. They also assessed various studies which focused on only one emotion at a time. For instance, “one study done by Seyeditabari et al. (2018), attempted to classify social media comments regarding a specific crisis event (5)”, with the aim to classify the emotion anger. Honing in on one emotion and using a random forest classifier allowed for higher accuracies than previous studies, reaching up to 90%.

Cleaning and Preprocessing:

The dataset we have chosen to work with is from Kaggle, where the authors have used a set of hashtags to categorize English Twitter messages into six basic emotions: anger, fear, joy, love, sadness, and surprise (1). The creators of this dataset have stated that the dataset is tokenized by white-spaces and then preprocessed by applying lower-casing and replacing user mentions and URLs with <username> and <url> placeholders, respectively (3). First we combine the test and training datasets used by CARER to attain a larger dataset of 18000 tweets, shuffling the dataset to randomize the order of the tweets from the training and test datasets. Next, in addition to the preprocessing of the data done by CARER, we remove all cases of English stopwords. Then we drop any rows in the dataframe which contain None or missing values. Next we remove any urls or special characters that may have been left in, and re-tokenize by white-spaces. Lastly, we re-divide the tweets into 80% training and 20% test.


Methodology:

We then deploy a CNN, ANN, and RNN on the cleaned data. For our CNN, we use the hyperparameters that SENN determined to be optimal - a batch size of 128, a learning rate of .01, and a dropout of 0.5. We also implement early stopping in all 3 neural networks to eliminate any time complexities and overfitting that could arise from iterating for too many epochs. We use the Adam optimizer, as it is computationally efficient, making it suitable for a dataset with 18000 tweets. For all of our neural networks, we embed the models with a 20000 word vocabulary where each word is represented by a 128-dimensioned vector, and all of our networks will use the softmax activation function to convert the data to probabilities, allowing for the tweets to be classified into one of the 6 categories of emotion.
For our CNN we use a 1-dimensional convolution operation to help detect patterns in the tweets. We use Global Maximum Pooling to reduce dimensionality, and use a dropout rate of 0.5, matching what was done in the SENN study. Additionally, we add a dense layer to combine features from the convolution layers.
For our ANN, we flatten the input into a 1-dimensional vector rather than a 2D matrix. Similar to our CNN, we add dense layers to learn from the previous layers and a dropout rate of 0.5.
Lastly, we implement our RNN the same as the above models, with the only difference being the LSTM layers. These layers process sequences of data while helping to preserve the long-term dependencies in the relationships between words in the tweets.

Evaluation of Results / Graphs:

The ANN was the worst performer of the 3, achieving a maximum accuracy of 79.00% with a learning rate of 0.001. Although this is a model that typically performs best on simpler datasets, this still was lower than expected. The ANN also seemed to be quite sensitive to hyperparameter tuning. The worst performance we saw from the ANN was with the optimizer learning rate set to 0.01, achieving an accuracy of only 32.7%. Despite it being the simplest of the 3 models, the ANN had an execution time of 67 seconds, making it the second fastest.
Our CNN performed well, achieving an accuracy of 91.333% on the test dataset. Since CNNs are most commonly used on image classification and pixel analysis, we had expected longer runtimes due to over-complicating the model. The actual runtime of the CNN was only 32.8 seconds making it the fastest of the 3 models. This is likely the result of the early stopping, as it only iterated over 3 epochs before terminating.
The RNN was the slowest of the 3 models. With a batch size of 32, the execution of each epoch took around 25 seconds, and since the validation loss was continuously improving, the RNN did not see early stopping resulting in a total execution time of 1330 seconds. On this execution the RNN attained an accuracy of 87.2%. However with a batch size of 128, the RNN was able to attain an accuracy of 92.22% and a runtime of 333 seconds, making it the both best performing model and the slowest.
Below we analyze the accuracy and loss seen by each model on the training and test data, over 3 epochs. We only display 3 epochs because it is the minimum number of epochs experienced by all models, with early stopping.

Conclusion:

In this study, we examine how well Convolutional Neural Networks (CNNs), Artificial Neural Networks (ANNs), and Recurrent Neural Networks (RNNs) can classify emotions in tweets. By using these neural network models, we attempt to address the unique challenges of tweets that arise from the character limit and informal language.
We discovered that there are unique advantages and disadvantages that come with each model. Our CNN performed quite well, achieving 91.16% accuracy on the test dataset. This shows that CNNs, although often used for image classification, are also good at identifying patterns in text. With early stopping, the CNN was the quickest, taking only 39 seconds to run, making it a great option for processing large amounts of text data efficiently.
In contrast, our ANN - often used for simpler classification tasks - underperformed. The highest accuracy achieved was 79.00%. This model showed more sensitivity to changes of hyperparameters, particularly with the learning rate. When set to 0.01, we were only able to achieve a 32% accuracy. The ANN execution time was only slightly slower than the CNN at 67 seconds. The lower accuracy suggests that an ANN might not be the best neural network to use for problems as complex as emotion classification in tweets.

Our RNN, used commonly in problems that depend on sequential data, achieved the highest accuracy - 92.22%. However, it had the longest execution time of the 3 models, at 513 seconds. In choosing a model to deploy, it is important to consider the trade-offs that come with a model with high accuracy but increased computational complexity.
Future work could explore approaches that combine the strengths of different models, as the SENN study did by combining a LSTM-RNN with a CNN. Additionally, future work could experiment with more sophisticated models, like transformers, to see if they would yield even higher emotion classification accuracy.

 References
(1) “Emotion Dataset for Emotion Recognition Tasks | Kaggle.” Kaggle: Your Machine Learning and Data Science Community, https://www.kaggle.com/datasets/parulpandey/emotion-dataset. Accessed 8 Aug. 2024.
(2) “ANN vs CNN vs RNN: Neural Networks Guide.” Levity | Streamline Your Freight Email Operations with AI Automation, https://levity.ai/blog/neural-networks-cnn-ann-rnn#:~:text=ANNs%20(Artificial%20Neural %20Networks)%20are,proficient%20in%20Natural%20Language%20Processing
(3) Elvis Saravia, Hsien-Chi Toby Liu, Yen-Hao Huang, Junlin Wu, and Yi-Shin Chen. 2018. CARER: Contextualized Affect Representations for Emotion Recognition. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 3687–3697, Brussels, Belgium. Association for Computational Linguistics
(4) E. Batbaatar, M. Li and K. H. Ryu, "Semantic-Emotion Neural Network for Emotion Recognition From Text," in IEEE Access, vol. 7, pp. 111866-111878, 2019, doi: 10.1109/ACCESS.2019.2934529.
(5) Shrivastava, Kush, Shishir Kumar, and Deepak Kumar Jain. "An effective approach for emotion detection in multimedia text data using sequence based convolutional neural network." Multimedia tools and applications 78 (2019): 29607-29639.
(6) “Learn FluCoMa.” Learn FluCoMa, https://learn.flucoma.org/learn/mlp-parameters/. Accessed 8 Aug. 2024.
(7) Kumawat, Tejpal. “Deep Learning Part 3: Parameter Initialization, BackPropagation, and Types of Error Involved | by Tejpal Kumawat | Medium.” Medium, Medium, 3 May 2023, https://medium.com/@tejpal.abhyuday/deep-learning-part-3-parameter-initialization-back propagation-and-types-of-error-involved-6aa4f4e589bb.
(8) Seyeditabari et al.2018] Armin Seyeditabari, Sara Levens, Cherie D Maestas, Samira Shaikh, James Igoe Walsh, Wlodek Zadrozny, Christina Danis, and Onah P Thompson. 2018. Cross corpus emotion classification using survey data.
(9) Organization, North American Geoscientists. “Delving into Convolutional Neural Networks (CNNs): Structure, Application, Limitations | by North American Geoscientists Organization | Medium.” Medium, Medium, 8 July 2023, https://medium.com/@northamericangeoscientistsorg/delving-into-convolutional-neural-n etworks-cnns-structure-application-limitations-49d3d95035ce.
  
